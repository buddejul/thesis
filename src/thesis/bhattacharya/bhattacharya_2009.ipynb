{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bhattacharya 2009 JASA\n",
    "\n",
    "## Problem\n",
    "\n",
    "Bhattacharya (2009) studies inference on the value of a linear program.\n",
    "The *population problem* is given by\n",
    "\n",
    "$$\n",
    "\\max_p \\gamma' p \\text{ subject to } Ap = \\gamma, p \\geq 0.\n",
    "$$\n",
    "Here, we have $m$ decision variables collected in the vector $p$.\n",
    "\n",
    "The analogous *sample problem* is given by \n",
    "$$\n",
    "\\min_p \\hat{\\gamma}' p \\text{ subject to } Ap = \\gamma, p \\geq 0.\n",
    "$$\n",
    "The only difference is that $\\gamma$ is treated as estimated by an estimator $\\hat{\\gamma}$.\n",
    "Importantly, all other constraints are nonrandom. That is, the polyhedron $P$ over which we maximize is non-random. \n",
    "\n",
    "In linear programs, if there is a solution, it is attained at an extreme point of the constraint set $P$.\n",
    "Informally, extreme points of $P$ are points in $P$, which are not attainable as a convex combination of any two other distinct points. \n",
    "For example, if $P=[0,1]^2$, the extreme points are the set $\\{(0,0), (1,0), (0,1), (1,1)\\}$.\n",
    "\n",
    "These extreme points correspond to the basic solutions of a linear program. \n",
    "Further, if the program has a solution it is attained at one of the *feasible* basic solutions.\n",
    "\n",
    "Denote the set of *feasible* basic solutions by $S = \\{z_1, \\ldots, z_{|S|}\\}$.\n",
    "We have $|S| \\leq {m \\choose M}$, where $m$ are the number of decision variables and $M$ is the number of equality constraints.\n",
    "\n",
    "<small>\n",
    "The bound follows from the requirement that at every basic solution m-M linearly independent constraint need to be active (and the symmetry of the binomial coefficient).\n",
    "</small>\n",
    "\n",
    "Hence, if we know $S$ we can simply think of maximizing over the finite set $S$.\n",
    "\n",
    "## Distribution Theory\n",
    "\n",
    "The main result is given in propositions 3 and 4.\n",
    "\n",
    "We assume \n",
    "$$\n",
    "\\sqrt{n}(\\hat{\\gamma} - \\gamma) \\to_d w = O_p(1)\n",
    "$$\n",
    "and denote the set of optimal solutions as \n",
    "$$\n",
    "\\Theta_0 = \\{z| z \\in S, \\gamma'z = v\\}\n",
    "$$\n",
    "which is finite and has $J$ elements, so $\\Theta_0 = \\{z_1, \\ldots, z_J\\}$.\n",
    "\n",
    "\n",
    "**Proposition 3** Assume $\\sqrt{n}(\\hat{\\gamma}-\\gamma)\\to_d w$ and that elements of $\\hat{\\gamma}$ are bounded with probability 1. Then\n",
    "$$\n",
    "\\sqrt{n}(\\hat{v} - v) = \\max_{z\\in\\Theta_0}\\{w'z\\} + o_p(1) = \\max_{1\\leq j\\leq J}\\{w'z_j\\} + o_p(1).\n",
    "$$\n",
    "\n",
    "Note this distribution is not pivotal: it depends on an unknown parameter, namely the set of optimal solutions $\\Theta_0$.\n",
    "Proposition 4 then states that we can instead use an estimator of this set given by\n",
    "$$\n",
    "\\hat{\\Theta}_n = \\{z^* \\in S: \\hat{\\gamma}'z^* \\geq \\max_{z\\in S} \\hat{\\gamma}'z - c_n\\}\n",
    "$$\n",
    "So these are all basic solutions which attain a similar sample value up to some tolerance.\n",
    "$c_n > 0$ is a tuning parameter and needs to be chosen by the researcher. \n",
    "The asymptotic theory requires $\\sqrt{n}c_n \\to \\infty$ and $c_n \\to 0$.\n",
    "\n",
    "If there is only a single optimal solution, so $|\\Theta_0| = 1$, then the asymptotic distribution is given by $\\sqrt{n}(\\hat{\\gamma} - \\gamma)z_o$.\n",
    "Hence, this is a linear combination of normal random variables with weights $z_0$. Generally, $z_0$ is unknown but can be conistently estimated.\n",
    "\n",
    "<small> Check the latter requirement is actually needed for proposition 4 (and maybe 3). </small>\n",
    "\n",
    "## Similarity to pretesting\n",
    "\n",
    "The approach above works by allowing for a slightly larger set of optimal solutions.\n",
    "The non-standard behavior arises from multiple optimal solutions.\n",
    "We can think of $\\hat{\\Theta}_n$ in terms of a pre-test whether there is a unique solution:\n",
    "Given some tolerance $c_n>0$\n",
    "- if the difference between the two values is too small, we cannot be sure that $\\hat{z}$ is the unique optimal solution;\n",
    "- if the difference is large enough, we can be fairly certain, that $\\hat{z}$ is the optimal solution.\n",
    "\n",
    "### Example in m = 2 dimensions\n",
    "\n",
    "### Example in m > 2 dimensions\n",
    "\n",
    "## Procedure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Illustrate Bhattacharya 2009 in a simple example.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
